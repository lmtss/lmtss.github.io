## 排序
主要是从GPU上的实时物理模拟方向考虑排序。  
实现排序功能除了自己编写以外，也可以使用先成的库(thrust、cub)。很多时候，一般人写出来的排序代码是不如成熟的库的，但是在实际应用中，库提供的函数可能不够灵活。   
最开始的时候过于小瞧排序算法的实现了，实际上内容很多。   
## thrust
thrust似乎是打算做成stl那样的东西，对我这种把c++当c写的人来说用着不太舒服。  
emmmmmm，gpu内存上的指针参与排序要经过转换为vector，而这个转换是copy，要消耗时间；相对的，从vector那里获取raw ptr消耗的时间很少。  
```cpp
thrust::device_ptr<int> p = thrust::device_pointer_cast(dev_ptr); // raw ptr转为thrust的指针
thrust::device_vector<int> vec(p, p + 1024);//转为vector，这一步有copy的消耗
thrust::sort(vec.begin(), vec.end());
p = vec.data();
dev_ptr = thrust::raw_pointer_cast(p);//获取vector实际内存地址
```  
用262144个数做测试，转换成vector部分消耗8.4ms，排序部分消耗55.5ms。或许是可以不用变成vector的。
## cub
[主页](http://nvlabs.github.io/cub/index.html)  
贴一下官方示例，示例中的是对key-value对排序。  
```cpp
#include <cub/cub.cuh>   // or equivalently <cub/device/device_radix_sort.cuh>
// Declare, allocate, and initialize device-accessible pointers for sorting data
int  num_items;          // e.g., 7
int  *d_keys_in;         // e.g., [8, 6, 7, 5, 3, 0, 9]
int  *d_keys_out;        // e.g., [        ...        ]
int  *d_values_in;       // e.g., [0, 1, 2, 3, 4, 5, 6]
int  *d_values_out;      // e.g., [        ...        ]
...
// Determine temporary device storage requirements
void     *d_temp_storage = NULL;
size_t   temp_storage_bytes = 0;
cub::DeviceRadixSort::SortPairs(d_temp_storage, temp_storage_bytes,
    d_keys_in, d_keys_out, d_values_in, d_values_out, num_items);
// Allocate temporary storage
cudaMalloc(&d_temp_storage, temp_storage_bytes);
// Run sorting operation
cub::DeviceRadixSort::SortPairs(d_temp_storage, temp_storage_bytes,
    d_keys_in, d_keys_out, d_values_in, d_values_out, num_items);
// d_keys_out            <-- [0, 3, 5, 6, 7, 8, 9]
// d_values_out          <-- [5, 4, 3, 1, 2, 0, 6]
```  
可以看出，并不需要像stl那样的迭代器、vector就能用。需要一个临时的数组。  
使用262144个数来测试，结果要55.5ms。还是有些惊讶的，本以为排序花销会很小，看来是我想的太简单了。
## cudpp
按照cudpp的官方介绍，他们的基数排序使用thrust做的。  
## 排序思路
没想到真要自己写排序代码，本以为用库就好，但似乎都不符我口味。GPU上的排序有基数排序、归并排序、双调排序、样本排序以及一大堆变种。相关内容很多很多，也有一些综述论文。我个人主要对全GPU端的排序感兴趣。  
## 基数排序 radix sort
基数排序在GPU上的实现很多，好像一般都是用它，相关论文也多，cpu上的基数排序大学课本估计都是会讲的。  
### [Fast sort on CPUs and GPUs: a case for bandwidth oblivious SIMD sort.](https://www.researchgate.net/publication/221213255_Fast_sort_on_CPUs_and_GPUs_a_case_for_bandwidth_oblivious_SIMD_sort)  
这篇讲了GPU、CPU上的radix sort和merge sort的实现和评估。  
上面说，  
合并排序可以使用SIMD友好的排序网络，随着SIMD宽度的增加，对SIMD友好的排序变得越来越有效。  
基数排序不是带宽友好的  
看起来作者对归并排序寄予厚望

作者介绍了几个版本的并行基数排序  
基础：  
计算每个基数的直方图(histogram)，再使用前缀和(扫描)操作将直方图合并成全局的直方图，得出每个key应写入的偏移量。  
利用共享内存做 写buffer：  
利用share memory做buffer，提高写入全局内存的效率，适应内存结构
