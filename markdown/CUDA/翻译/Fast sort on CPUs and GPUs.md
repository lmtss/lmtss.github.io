翻译学习[Fast sort on CPUs and GPUs: a case for bandwidth oblivious SIMD sort.](https://www.researchgate.net/publication/221213255_Fast_sort_on_CPUs_and_GPUs_a_case_for_bandwidth_oblivious_SIMD_sort)  
谷歌翻译很好用
## 3 在现代处理器上排序算法的表现

尽管不同排序算法的理论计算复杂度会对性能产生一定影响，但它们使用不同硬件功能的效率通常在性能方面具有决定性作用。 随着内存大小的增加，内存数据库现在很常见，因此I/O并不是主要限制。现在，性能限制已转移到体系结构中可用的计算和主内存资源。现在，我们说明一些最近的体系结构改进及其在数据库操作环境中对排序性能的影响。
## 3.1 线程层面和数据层面的并行
现代处理器通过（a）添加更多内核以利用线程级并行性，以及（b）添加SIMD单元以利用数据级并行性来提高了计算能力。 已经针对不同的多核体系结构提出了许多排序算法的线程并行实现。 自然地，诸如合并和快速分类之类的许多分类涉及并行地组合或分割不同的数据块。 其他排序，例如基数排序，可以通过阻止输入数据并使用全局直方图更新来协调块之间进行并行化（请参阅Blelloch [6]）。 这些已显示出可以在CPU和GPU架构上很好地扩展。  
在某些排序算法中，数据级并行性很难利用。 为了有效地执行SIMD，必须将要操作的数据连续放置在内存中。 在没有连续访问的情况下，需要对内存的收集/分散1，这在大多数体系结构上都很慢。 例如，基数排序通常涉及到常见的直方图更新和不规则的内存访问以重新排列数据。 这两种方法本质上都不适合SIMD执行。 已经提出了对SIMD更友好的基数排序变体[27]； 但是它们需要更多指令才能执行。 另一方面，`合并排序可以使用SIMD友好的排序网络`[9]。 随着SIMD宽度的增加，对SIMD友好的排序变得越来越有效。  
## 3.2 内存带宽
排序从根本上涉及重新安排驻留在内存中的数据，因此通常会占用大量内存。内存带宽的提高没有现代处理器的计算能力大，并且未来每核的带宽有望进一步下降[21]。要求高内存带宽的算法很可能会成为带宽限制，因此就内核数和SIMD宽度而言停止扩展。为了弥合应用程序带宽需求和可用带宽之间的差距，架构以CPU上的缓存层次结构和GPU上的共享内存的形式引入了片上本地存储。如果正在处理的数据集适合该存储，则不使用主内存带宽；否则从主存储器读取和写入数据。重新设计了排序算法以使用此类存储区域。就带宽使用而言，可以使合并排序非常有效，通过多路合并实现[11]仅需要两次读取和两次写入数据，即可限制工作集以适合高速缓存。`基数排序不是带宽友好的`。如果输入数据远大于缓存大小，则必须在每次通过中读写每个输入键。  
## 3.3 
## 4 基数排序
在本节中，我们将在4.1节中描述基本的基数排序算法及其并行实现。 在第4.2节中，我们然后提出了一种基于缓冲区的方案，以使基数排序体系结构友好，并且还描述了基于流拆分(stream splits)的先前本地排序方法。 然后，我们将在第4.3和4.4节中描述基数排序的最佳CPU和GPU实现，并提供一个性能模型来分析其性能。  
## 4.1 基础平行算法 (英语渣，读了半天读不懂)
线程级并行性易于提取，将要排序的输入分解为块，并为每个块获取局部直方图。然后将这些局部直方图组合成全局直方图，然后使用全局直方图进行重排。将局部直方图转换为全局直方图的过程是一个前缀和（扫描）操作，该操作很容易并行化[6，27]。  
对数字中的每一位数(For all digits in the number)(应该是指256879 -> 2 5 6 8 7 9 这样)  
步骤1：将输入划分为 T 个线程，每个线程计算独自的直方图。  
步骤2：使用前缀和操作将直方图合并为全局的直方图。我们现在有每个线程的每个基数应写入的起始偏移量。(指的是1 2 2 4 -> 直方图 1 2 0 1 -> 全局直方图 1 3 3 4)  
步骤3：每个线程计算每个key的最终偏移量为下面两个的和：  
(1) 步骤2中计算的偏移量
(2) 当前key之前的，基数相同的key的数量，的直方图(0 0 1 0)  
## 4.2 架构友好的实现
高效实现基数排序的主要瓶颈是在计算直方图和重排阶段的不规律的内存访问。尤其是，步骤3中，涉及到使用贷款不友好的方式来重排一个大的数组(一般存在于主存)，。  
通过改善分散的位置，我们可以减少内存带宽利用率以及内存访问延迟。通过利用本地存储（CPU架构中的缓存或GPU上的共享内存），我们可以将全局内存分散转换为本地存储分散。这可以通过两种不同的方式来实现：(1)在本地存储中缓冲对主存储器的不同高速缓存行宽区域(64字节)的写操作(第4.2.1节)，并以连续的方式将其写入主存储器，或者(2)根据考虑的基数，对适合本地存储器的小数据块进行本地排序(第4.2.2节)。  
## 4.2.1 基于buffer的策略
基于缓冲区的方案的基本思想是将属于同一基数的元素收集到本地存储的缓冲区中，并且仅在积累了足够的元素时才将缓冲区从本地存储写出到全局内存中。 这有两个优点：（1）现在，对全局内存的所有写入都比单个元素具有更大的粒度，从而提高了带宽利用率；（2）在任何时候，写入的内存页面与 基数。 由于对每个基数的所有写操作都是连续的，因此一旦打开内存页面以写入具有特定基数的键，就会继续重复使用该页面，直到页面已满或所有属于该基数的值都被写出为止。 只要调整基数的数量以适合体系结构中TLB的大小，此方案就会导致很少的页面丢失。  
在基于缓存的结构(cache-based architecture)上，基数排序的直接实现可以隐式执行缓冲，因为缓存被安排到映射到内存总线宽度的缓存行中，并且仅当对不同内存区域的写入访问同一缓存行时才被写出。但是，在我们的实验中，我们发现幼稚的实现导致大量缓存冲突未命中。对于各种各样的输入分布都可以观察到这种现象。由于属于不同基数的缓冲区不存在于连续的内存位置中，因此会发生此类未命中，因此取决于确切的内存地址，它们可能映射到同一高速缓存行。完全关联的高速缓存（对单个内存地址的映射位置没有限制）可以消除冲突遗漏。但是，完全关联的高速缓存在架构上过于昂贵而无法构建。为了消除缓存冲突，我们建议并使用`软件管理的缓冲区`，并在存在所有缓冲区的内存中分配连续的区域，并使用软件对其进行管理。  
软件管理的缓冲区：